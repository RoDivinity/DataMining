---
title: "Untitled"
author: "Linh Nguyen Madeline Lin"
date: "4/7/2019"
output: pdf_document
---
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(gamlr)
library(dplyr)
```

# Exercise 3
## Exercise 3.1
### Build the best predictive model possible for price.
```{r setup_3.1, echo=FALSE, warning=FALSE}
urlfile<-'https://raw.githubusercontent.com/RoDivinity/DataMining/master/Data/greenbuildings.csv'
gb<-read.csv(url(urlfile))
#clean data
gb =na.omit(gb)

#allow lasso regression to converge
gb$size = gb$size/10000

#clean data by deleting the data with occupacy rate equal to 0%
gb <- subset(gb,(gb$leasing_rate != 0))
```

I preprocess the data as follow:

  1. Clear out all the observations with missing values in the data. 
  
  2. Scale down the size by $\frac{1}{10000}$ to abide the lasso computation's requirement so it can converge. 
  
  3. Omit building with leasing rate = 0 because it makes no sense to charge a rent for unoccupied buildings (they are either under construction or abandoned or other reasons)
  

To find best predictive model, I will deploy stepwise regression and lasso regression.

  a. Stepwise regression using LEED and EnergyStar explicitly and using green rating (implying LEED and Energy Star is green certified). In both models, I started with the null model by regressing rent on one, followed by adding new variables in the forward selection method. This is the baseline model to run stepwise regression

Model using LEED and EnergyStar explicitly:

```{r stepwise with LEED & Energy, echo=FALSE, warning=FALSE}
## stepwise model with LEED & Energy (model 1)
full = lm(Rent ~ .-CS_PropertyID-green_rating, data=gb)
null = glm(Rent~1, data=gb)
fwd = step(null, scope=formula(full), dir="forward", trace = FALSE)
big  = lm(Rent ~ (.-CS_PropertyID-green_rating)^2, data=gb)
stepwise = step(null, scope=formula(big), dir="both", trace = FALSE)
#45 used, null = Forward, then stepwise 
model1 = formula(stepwise)
model1
```

Model using green certified category:
```{r model2, echo=FALSE, warning=FALSE}
## stepwise with green rating (model 2)
full = lm(Rent ~ .-CS_PropertyID-LEED-Energystar, data=gb)
null = lm(Rent~1, data=gb)
fwd = step(null, scope=formula(full), dir="forward", trace = FALSE)
big  = lm(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb)
stepwise = step(null, scope=formula(big), dir="both", trace = FALSE)
#44 used, null = Forward, then stepwise 
model2 = formula(stepwise)
model2
```

  b. Lasso regression using LEED and EnergyStar separately, then second lasso regression combining them into a single "green certified" category. I created sparse matrix including all interactions terms then run lasso regression on it


```{r model3_lasso, echo=FALSE, warning=FALSE}
## Gamma Lasso with LEED & Energy (model 3)
gbx = sparse.model.matrix(Rent ~ (.-CS_PropertyID-green_rating)^2, data=gb)[,-1] 
gby = gb$Rent
gblasso = gamlr(gbx, gby, lambda.min.ratio=0.00001)
plot(gblasso) # the path plot!
min1 <- which.min(AICc(gblasso))
```
Minimum AIC occurs at segment `r min1`.

Thus, coefficients chose in the model are:
```{r model3, echo=FALSE, warning=FALSE}
gbbeta = coef(gblasso)
# 184 used in Lasso
# sum(gbbeta!=0)
p1 <- dimnames(gbbeta)[[1]]
p2 <- c()
for (i in c(1:length(gbbeta))){
  p2 <- c(p2, as.list(gbbeta)[[i]])
}
model3 = c("Rent ~ ")
for (i in c(2:length(gbbeta))){
  if (p2[i] != 0){
    if (model3 == "Rent ~ "){
      model3 = paste(model3, p1[i])
    }
    else{
      model3 = paste(model3,"+", p1[i])
    }
  }
}
model3 <- as.formula(model3)
model3
#size <- length(p2)
#size
```



For Lasso regression with green-certified variable:

```{r model4_lasso, echo=FALSE, warning=FALSE}
## Gamma Lasso model 2.2 Green-rating
gbx = sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb)[,-1] 
gby = gb$Rent
gblasso = gamlr(gbx, gby, lambda.min.ratio=0.00001)
plot(gblasso) # the path plot!
min2 <- which.min(AICc(gblasso))
```
Minimum AIC occurs at segment `r min2`.

Coefficients chose in the model are:

```{r model4, echo=FALSE, warning=FALSE}
gbbeta2 = coef(gblasso)
p1 <- dimnames(gbbeta2)[[1]]
p2 <- c()
for (i in c(1:length(gbbeta2))){
  p2 <- c(p2, as.list(gbbeta2)[[i]])
}
model4 = c("Rent ~ ")
for (i in c(2:length(gbbeta2))){
  if (p2[i] != 0){
    if (model4 == "Rent ~ "){
      model4 = paste(model4, p1[i])
    }
    else{
      model4 = paste(model4,"+", p1[i])
    }
  }
}
model4 <- as.formula(model4)
model4
#size2 <- length(p2)
#size2
```

  c. To measure predictive power, I employed k-fold cross validation. 
I set k = 15 and calculated 4 models' CVs. Stepwise models has smaller CVs compared to Lasso models. Between 2 stepwise model, the one with a single green certified category has lower CV.

In conclusion, the stepwise model with "green certified" category had the minimum CV, and therefore it is the best predictive model possible for rent price.

```{r RMSE_comparison, echo=FALSE, warning=FALSE}
N = nrow(gb)
# Create a vector of fold indicators
K = 15
fold_id = rep_len(1:K, N)  # repeats 1:K over and over again
fold_id = sample(fold_id, replace=FALSE) # permute the order randomly
step_err_save = rep(0, K)
step_err_save2 = rep(0, K)
lasso_err_save = rep(0, K)
lasso_err_save2 = rep(0, K)
for(i in 1:K) {
  train_set = which(fold_id != i)
  y_test = gb$Rent[-train_set]
  step_model = lm(model1, data=gb[train_set,])
  step_model2 = lm(model2, data=gb[train_set,])
  lasso_model = lm(model3, data=gb[train_set,])
  lasso_model2 = lm(model4, data=gb[train_set,])
  
  yhat_test1 = predict(step_model, newdata=gb[-train_set,])
  step_err_save[i] = mean((y_test - yhat_test1)^2)
  
  yhat_test2 = predict(step_model2, newdata=gb[-train_set,])
  step_err_save2[i] = mean((y_test - yhat_test2)^2)
  
  yhat_test3 = predict(lasso_model, newdata=gb[-train_set,])
  lasso_err_save[i] = mean((y_test - yhat_test3)^2)
  
  yhat_test4 = predict(lasso_model2, newdata=gb[-train_set,])
  lasso_err_save2[i] = mean((y_test - yhat_test4)^2)
}
# RMSE
c(sqrt(mean(step_err_save)),sqrt(mean(step_err_save2)),sqrt(mean(lasso_err_save)),sqrt(mean(lasso_err_save2)))
```

### Use this model to quantify the average change in rental income per square foot (whether in absolute or percentage terms) associated with green certification, holding other features of the building constant.

```{r result, echo=FALSE, warning=FALSE}
step_model2 = lm(model2, data=gb)
temp = coef(step_model2) %>% round(3)
temp 
```

Holding all other significant features of the building fixed, green certified (LEED and EnergyStar combined) buildings are expected to be `r temp["green_rating"]` $\$/ft^{2}$ per year more expensive than non-green buildings.

### Assess whether the "green certification" effect is different for different buildings, or instead whether it seems to be roughly similar across all or most buildings.

  As mentioned, the stepwise model with collapsed category of green certified has the best predictive power. Green certification buildings with amenities is `r temp["green_rating:amenities"]` $\$/ft^{2}$ per year. It less than green certification buildings without amenities. Hence, "green certification" effect is different for buildings of with and without amenities. 

  One possible explanation is that the green buildings with amenities are normally considered as commercial buildings, so the buildings need to pay the energy fee according to different scheme compared to residential buildings. It can be that commercial rate is higher than residential rate. Thus, residents in the green buildings with amenities must pay more than those in the green buildings without amenities. Therefore green buildings with amenities have incentive to lower the rent fee to captivate more potential renters.

#Question 2:






##Probelm Summary:





The problem asks us to listen to the podcast from Planet Money. This podcast is an interview between Charles Wheelan (the
guest, author of the book "Naked Statistics") and Robert Smith together with Jacob Goldstein (the hosts). The topic of 
this interview is about "What causes What". During the interview, they have mentioned correlation and causation of different stories, including children's education, women's health, city's crime, and so forth. Crime, which is one of the topics discussed in the interview, is the problem we need to address in this question.

So, what we need to do is to use our knowledge of statistical learniing to answer the following four questions related to econometrics based on figures and tables provided in the questions.





###1) Why can’t I just get data from a few different cities and run the regression of “Crime” on “Police” to understand how more cops in the streets affect crime? (“Crime” refers to some measure of crime rate and “Police” measures the number of cops in a city.)





Intuitively, if we want to explore the relationship between "Crime" and "Police", what we should do is to regress "Crime" on "Police" and expect that the coefficient of "Police" would be negative since normally more cops in the street will lead to a lower crime rate. However, from the dicussion of Wheelan and Smith, we can see that Smith saying "it's really hard to tease out because obviously high-crime cities have an incentive to hire a lot of cops". He meant that usually more cops will lead to low crime rate. But, it is also possible that high-crime rate cities will have more cops. 

There exists a two-side interaction for both "Crime" and "Police". So it is kind of messey to merely run the regression of "Crime" on "Police". If we use a professional term learned from the Econometrics here, it should be called "Endogeneity". "Simultaneity" leads to a biased simple OLS regression. There should be some omitted variables which do not have an effect on crime but have an effect on police. What need to find the instrument variable in order to find a causal effect between "Police" and "Crime".


###2) How were the researchers from UPenn able to isolate this effect? Briefly describe their approach and discuss their result in the “Table 2” below, from the researcher's paper.





The researchers from UPenn isolated this effect by using "Instrument Variable Method". In brief, instrument variable(Z) is corelated to the X variable, but uncorelated to u(residules) in the regression. So here, they pick "the Terrorism Alert System" as the instrument variable because terrorism is corelated to police but has nothing to do with crime. They also select the area Washington, D.C. because it is a typical area to be a terrorism target. 


Therefore, on orange alert days, they can explore what happens to street crime when there are extra police on the streets because of terrorism instead of crime. If the street crime still goes down, then we can say that police have a positive deterrence on the street crime because police can make the streets safer and let things like murder, robbery, assult go down.


As it is indicated in the "Table 2" from the researcher's paper, their results are as follows:


(1) The crime rate indeed decreased during orange alert days when more cops were on the streets.


(2) Specifically, they found that high alert days were correlated with approximately an average of 7.316 unit decrease in the number of crimes committed, and, approximately an average of 6.046 unit decrease in the number of crimes committed if including a log midday Metro ridership, holding all else fixed.


(3) Both of these two above estimates were statistically significant at the 5% level of significance.


(4) With including a log midday Metro ridership, the coefficient of high-alert variable was a little bit smaller. Additionally, one unit increase in Metro ridership would lead to approximately an average of 17 crimes per day, holding all else fixed.

(5) The above estimate was statistically significant at the 1% level of significance.






###3)Why did they have to control for Metro ridership? What was that trying to capture?





In the above question, there is actual one problem needs to be addressed. "the Terrorism Alert System", as an instrument variable, should not effect another variable which has an impact on "Crime". To be more specific, let's say becuase of terrorism, it is likely that robbers hide in their rooms because they're afraid of the elevated terror level, or, some tourisits from other cities don't dare to visit Washington, D.C. result from the dangerous environment as mentioned in the case. These kind of changes will lead to a lower crime rate because the number of people who commit crime and the number of people who are suffered from crime both decrease. In one word, there will be less chances for crime, resulting in a lower crime rate.


Consequently, researchers had to deal with this problem. They came up with a solution to check the number of victims by looking at ridership levels on the Metro system. Since people who visit the city usually use public transportation such as Metro, we can check whether the number of victims change or not on high-terror days. Logically, if we rerun the regression, and, the coefficient of high-alert variable is still negative after considering this factor, then we can say that police indeed has a positive impact on a lower crime rate.


As we can discover from the Table 2, by including the varibale of log midday ridership, the coefficient of the high-alert variable is still smaller than zero. This result teases out the possibility that terrorism effects the crime rate. By using the control variable Metro ridership to capture the number of victims, the researchers can verify that the accuracy of the impact that police has on crime is not confounded by the change of the number of victims.





###4)Below I am showing you "Table 4" from the researchers' paper. Just focus on the first column of the table. Can you describe the model being estimated here? What is the conclusion?




The description the model being estimated here:

The model is a fixed effects specification model. It includes panel data set of different districts and add one variable of log midday metro ridership. Specifically, it runs a regression of estimating the effect police has on crime in different districts of Washington, D.C. during high alert days, holding all else fixed.

The conclusion for analyzing Column 1 are:

(1) During high-alert days, District 1 has the largest decrease, approximately an average of 2.621 units, in crime when there is one unit of police increase, holding all else fixed.
The cofficient is statistically significant at 1% level.


(2) As for other districts, one unit of police increase only leads to approximately an average of 0.571 units of decrease in crime, holding all else fixed.
The cofficient is not statistically significant at 1% level as the confidence interval lies on the coefficient of zero.

(3) We can suppose that District 1 is the area where most places of security importance exist. For example, the White House, Supreme Court and Capitol and so on. Therefore, masses of police are there to protect the security. Owing to the large amount of police officers, there is a strong statistically significant decrease in the crime rate during this high-alert days.





